{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "182ecf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "95ac8c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/anry/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9aa8ed5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://medium.com/swlh/multi-label-text-classification-with-scikit-learn-and-tensorflow-257f9ee30536\n",
    "def decontract(sentence):\n",
    "    sentence = re.sub(r\"n\\'t\", \" not\", sentence)\n",
    "    sentence = re.sub(r\"\\'re\", \" are\", sentence)\n",
    "    sentence = re.sub(r\"\\'s\", \" is\", sentence)\n",
    "    sentence = re.sub(r\"\\'d\", \" would\", sentence)\n",
    "    sentence = re.sub(r\"\\'ll\", \" will\", sentence)\n",
    "    sentence = re.sub(r\"\\'t\", \" not\", sentence)\n",
    "    sentence = re.sub(r\"\\'ve\", \" have\", sentence)\n",
    "    sentence = re.sub(r\"\\'m\", \" am\", sentence)\n",
    "    return sentence\n",
    "\n",
    "def removePunctuation(sentence): \n",
    "    sentence = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n",
    "    sentence = re.sub(r'[.|,|)|(|\\|/]',r' ',sentence)\n",
    "    sentence = sentence.strip()\n",
    "    sentence = sentence.replace(\"\\n\",\" \")\n",
    "    return sentence\n",
    "\n",
    "def removeNumber(sentence):\n",
    "    alpha_sent = \"\"\n",
    "    for word in sentence.split():\n",
    "        alpha_word = re.sub('[^a-z A-Z]+', '', word)\n",
    "        alpha_sent += alpha_word\n",
    "        alpha_sent += \" \"\n",
    "    alpha_sent = alpha_sent.strip()\n",
    "    return alpha_sent\n",
    "\n",
    "def removeStopWords(sentence):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    sentence = sentence.split(' ')\n",
    "    filtered_sentence = [w for w in sentence if not w.lower() in stop_words]\n",
    "    return \" \".join(filtered_sentence)\n",
    "    \n",
    "\n",
    "def stemming(sentence):\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    stemmedSentence = \"\"\n",
    "    for word in sentence.split():\n",
    "        stem = stemmer.stem(word)\n",
    "        stemmedSentence += stem\n",
    "        stemmedSentence += \" \"\n",
    "    stemmedSentence = stemmedSentence.strip()\n",
    "    return stemmedSentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5e6d2fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = pd.read_csv('../datasets/train_preprocessed.csv').dropna()\n",
    "X_train,y_train = datasets[\"content\"].astype(\"string\"),datasets[\"sentiment\"].astype(\"category\").cat.codes\n",
    "\n",
    "maxlen = max(X_train.apply(lambda x:len(x)))+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c64bd698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = X_train.apply(lambda x: decontract(x))\n",
    "# X_train = X_train.apply(lambda x: removePunctuation(x))\n",
    "# X_train = X_train.apply(lambda x: removeNumber(x))\n",
    "# X_train = X_train.apply(lambda x: removeStopWords(x))\n",
    "# X_train = X_train.apply(lambda x: stemming(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "63415c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words=10000, lower=True)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_train = pad_sequences(X_train, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8015eb6b-b89e-4f30-a786-b530f1516a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # #class weights\n",
    "# # counts = Counter(y_train)\n",
    "# # weights = {i:1/j for i,j in counts.items()}\n",
    "# #f1 loss\n",
    "# def macro_double_soft_f1(y, y_hat):\n",
    "#     \"\"\"Compute the macro soft F1-score as a cost (average 1 - soft-F1 across all labels).\n",
    "#     Use probability values instead of binary predictions.\n",
    "#     This version uses the computation of soft-F1 for both positive and negative class for each label.\n",
    "    \n",
    "#     Args:\n",
    "#         y (int32 Tensor): targets array of shape (BATCH_SIZE, N_LABELS)\n",
    "#         y_hat (float32 Tensor): probability matrix from forward propagation of shape (BATCH_SIZE, N_LABELS)\n",
    "        \n",
    "#     Returns:\n",
    "#         cost (scalar Tensor): value of the cost function for the batch\n",
    "#     \"\"\"\n",
    "#     y = tf.cast(y, tf.float32)\n",
    "#     y_hat = tf.cast(y_hat, tf.float32)\n",
    "#     tp = tf.reduce_sum(y_hat * y, axis=0)\n",
    "#     fp = tf.reduce_sum(y_hat * (1 - y), axis=0)\n",
    "#     fn = tf.reduce_sum((1 - y_hat) * y, axis=0)\n",
    "#     tn = tf.reduce_sum((1 - y_hat) * (1 - y), axis=0)\n",
    "#     soft_f1_class1 = 2*tp / (2*tp + fn + fp + 1e-16)\n",
    "#     soft_f1_class0 = 2*tn / (2*tn + fn + fp + 1e-16)\n",
    "#     cost_class1 = 1 - soft_f1_class1 # reduce 1 - soft-f1_class1 in order to increase soft-f1 on class 1\n",
    "#     cost_class0 = 1 - soft_f1_class0 # reduce 1 - soft-f1_class0 in order to increase soft-f1 on class 0\n",
    "#     cost = 0.5 * (cost_class1 + cost_class0) # take into account both class 1 and class 0\n",
    "#     macro_cost = tf.reduce_mean(cost) # average on all labels\n",
    "#     return macro_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6cc4ed1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Flatten, LSTM, Input,Embedding,Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "max_words =10000\n",
    "\n",
    "deep_inputs = Input(shape=(maxlen,))\n",
    "\n",
    "embedding_layer = Embedding(max_words,120, trainable=True,)(deep_inputs)# weights=[embedding_matrix],\n",
    "\n",
    "\n",
    "LSTM_Layer_1 = LSTM(\n",
    "    units = 120,\n",
    "    activation=\"tanh\",\n",
    "    name = 'lstm_layer_1',\n",
    "    recurrent_activation=\"sigmoid\",\n",
    "    use_bias=True,\n",
    "    dropout=0.1,\n",
    "    return_sequences=True)(embedding_layer)\n",
    "\n",
    "LSTM_Layer_2 = LSTM(\n",
    "    units = 120,\n",
    "    activation=\"tanh\",\n",
    "    name = 'lstm_layer_2',\n",
    "    recurrent_activation=\"sigmoid\",\n",
    "    use_bias=True,\n",
    "    dropout=0.1)(LSTM_Layer_1)\n",
    "\n",
    "\n",
    "dense_layer_1 = Dense(13, activation='softmax')(LSTM_Layer_2)#softmax because we have multi-class classification\n",
    "model = Model(inputs=deep_inputs, outputs=dense_layer_1)\n",
    "\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath=\"./checkpoints/lstm_augmented/\",save_best_only=True,save_weights_only=False)\n",
    "]\n",
    "\n",
    "model.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), \n",
    "              metrics=[  \n",
    "                  tf.keras.metrics.TruePositives(name='tp'),\n",
    "                  tf.keras.metrics.FalsePositives(name='fp'),\n",
    "                  tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "                  tf.keras.metrics.FalseNegatives(name='fn'), \n",
    "                  tf.keras.metrics.Precision(name='precision'),\n",
    "                  tf.keras.metrics.Recall(name='recall'),\n",
    "                  tf.keras.metrics.CategoricalAccuracy(name='acc'),\n",
    "                  tf.keras.metrics.AUC(name='auc'),\n",
    "                  tfa.metrics.F1Score(num_classes=13,average='macro',threshold = 0.5)\n",
    "              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "07d544c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "748/748 [==============================] - ETA: 0s - loss: 2.1354 - tp: 237.0000 - fp: 216.0000 - tn: 286848.0000 - fn: 23685.0000 - precision: 0.5232 - recall: 0.0099 - acc: 0.2772 - auc: 0.7719 - f1_score: 0.0130"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_38_layer_call_fn, lstm_cell_38_layer_call_and_return_conditional_losses, lstm_cell_39_layer_call_fn, lstm_cell_39_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./checkpoints/lstm_augmented/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./checkpoints/lstm_augmented/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f8a640e09d0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f8a5c219a30> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "748/748 [==============================] - 268s 351ms/step - loss: 2.1354 - tp: 237.0000 - fp: 216.0000 - tn: 286848.0000 - fn: 23685.0000 - precision: 0.5232 - recall: 0.0099 - acc: 0.2772 - auc: 0.7719 - f1_score: 0.0130 - val_loss: 2.0420 - val_tp: 186.0000 - val_fp: 163.0000 - val_tn: 71609.0000 - val_fn: 5795.0000 - val_precision: 0.5330 - val_recall: 0.0311 - val_acc: 0.3088 - val_auc: 0.7977 - val_f1_score: 0.0424\n",
      "Epoch 2/2\n",
      "748/748 [==============================] - ETA: 0s - loss: 1.9004 - tp: 1678.0000 - fp: 1191.0000 - tn: 285873.0000 - fn: 22244.0000 - precision: 0.5849 - recall: 0.0701 - acc: 0.3632 - auc: 0.8305 - f1_score: 0.0792"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_38_layer_call_fn, lstm_cell_38_layer_call_and_return_conditional_losses, lstm_cell_39_layer_call_fn, lstm_cell_39_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./checkpoints/lstm_augmented/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./checkpoints/lstm_augmented/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f8a640e09d0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f8a5c219a30> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "748/748 [==============================] - 262s 350ms/step - loss: 1.9004 - tp: 1678.0000 - fp: 1191.0000 - tn: 285873.0000 - fn: 22244.0000 - precision: 0.5849 - recall: 0.0701 - acc: 0.3632 - auc: 0.8305 - f1_score: 0.0792 - val_loss: 1.9938 - val_tp: 301.0000 - val_fp: 253.0000 - val_tn: 71519.0000 - val_fn: 5680.0000 - val_precision: 0.5433 - val_recall: 0.0503 - val_acc: 0.3267 - val_auc: 0.8093 - val_f1_score: 0.0646\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8a4111fd30>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,pd.get_dummies(y_train),validation_split=0.2,batch_size=32,epochs = 2,workers = -1,callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "078dadba-9108-48aa-b40b-920249c0cab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('./weights/lstm_augmented/saved_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "07e4957a-6fbb-4c27-bb5c-b63e2ccadafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_38_layer_call_fn, lstm_cell_38_layer_call_and_return_conditional_losses, lstm_cell_39_layer_call_fn, lstm_cell_39_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./full_models/lstm_augmented/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./full_models/lstm_augmented/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f8a640e09d0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f8a5c219a30> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.models.save_model(model,'./full_models/lstm_augmented')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2305cd9-4d4d-4e20-949e-1f8b43063218",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "907a6839-c0ad-4b96-aab6-e885be91ae44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "datasets = pd.read_csv('../datasets/test_preprocessed.csv').dropna()\n",
    "X_test,y_test = datasets[\"content\"].astype(\"string\"),datasets[\"sentiment\"].astype(\"category\").cat.codes\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "X_test = pad_sequences(X_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f4804223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        73\n",
      "           1       0.00      0.00      0.00       118\n",
      "           2       0.00      0.00      0.00       538\n",
      "           3       0.00      0.00      0.00       501\n",
      "           4       0.00      0.00      0.00       586\n",
      "           5       0.15      0.26      0.19      1719\n",
      "           6       0.00      0.00      0.00       873\n",
      "           7       0.14      0.10      0.12      1268\n",
      "           8       0.25      0.50      0.33      2825\n",
      "           9       0.00      0.00      0.00      1007\n",
      "          10       0.13      0.06      0.09      1704\n",
      "          11       0.00      0.00      0.00       722\n",
      "          12       0.21      0.32      0.25      2790\n",
      "\n",
      "    accuracy                           0.20     14724\n",
      "   macro avg       0.07      0.10      0.08     14724\n",
      "weighted avg       0.13      0.20      0.15     14724\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#normal lstm\n",
    "model.load_weights('weights/lstm_without_weights/saved_weights.h5')\n",
    "y_pred = tf.argmax(model.predict(X_test),axis = 1)\n",
    "print(classification_report(y_test, y_pred,zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "36c285ef-b83e-4e3c-b862-b0cbd9228827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.01      0.04      0.01        73\n",
      "           1       0.01      0.08      0.02       118\n",
      "           2       0.03      0.03      0.03       538\n",
      "           3       0.00      0.00      0.00       501\n",
      "           4       0.04      0.18      0.07       586\n",
      "           5       0.15      0.05      0.08      1719\n",
      "           6       0.09      0.03      0.04       873\n",
      "           7       0.12      0.24      0.16      1268\n",
      "           8       0.26      0.38      0.31      2825\n",
      "           9       0.07      0.05      0.06      1007\n",
      "          10       0.14      0.15      0.14      1704\n",
      "          11       0.07      0.03      0.04       722\n",
      "          12       0.21      0.01      0.02      2790\n",
      "\n",
      "    accuracy                           0.13     14724\n",
      "   macro avg       0.09      0.10      0.08     14724\n",
      "weighted avg       0.15      0.13      0.11     14724\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#weighted lstm\n",
    "model.load_weights('weights/lstm_with_weights/saved_weights.h5')\n",
    "y_pred = tf.argmax(model.predict(X_test),axis = 1)\n",
    "print(classification_report(y_test, y_pred,zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a33a6909-cd38-47f7-a097-ebdf2b342a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        73\n",
      "           1       0.00      0.00      0.00       118\n",
      "           2       0.00      0.00      0.00       538\n",
      "           3       0.00      0.00      0.00       501\n",
      "           4       0.05      0.06      0.05       586\n",
      "           5       0.14      0.20      0.17      1719\n",
      "           6       0.14      0.00      0.01       873\n",
      "           7       0.16      0.09      0.12      1268\n",
      "           8       0.24      0.42      0.30      2825\n",
      "           9       0.09      0.07      0.08      1007\n",
      "          10       0.13      0.09      0.10      1704\n",
      "          11       0.03      0.02      0.03       722\n",
      "          12       0.22      0.26      0.24      2790\n",
      "\n",
      "    accuracy                           0.18     14724\n",
      "   macro avg       0.09      0.09      0.08     14724\n",
      "weighted avg       0.15      0.18      0.15     14724\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#f1 loss lstm\n",
    "model.load_weights('weights/lstm_f1_loss/saved_weights.h5')\n",
    "y_pred = tf.argmax(model.predict(X_test),axis = 1)\n",
    "print(classification_report(y_test, y_pred,zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "28b4c05b-9dd8-4e9d-86cd-f3de3d78dc6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        73\n",
      "           1       0.00      0.00      0.00       118\n",
      "           2       0.00      0.00      0.00       538\n",
      "           3       0.00      0.00      0.00       501\n",
      "           4       0.05      0.06      0.05       586\n",
      "           5       0.14      0.20      0.17      1719\n",
      "           6       0.14      0.00      0.01       873\n",
      "           7       0.16      0.09      0.12      1268\n",
      "           8       0.24      0.42      0.30      2825\n",
      "           9       0.09      0.07      0.08      1007\n",
      "          10       0.13      0.09      0.10      1704\n",
      "          11       0.03      0.02      0.03       722\n",
      "          12       0.22      0.26      0.24      2790\n",
      "\n",
      "    accuracy                           0.18     14724\n",
      "   macro avg       0.09      0.09      0.08     14724\n",
      "weighted avg       0.15      0.18      0.15     14724\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#augmented lstm\n",
    "model.load_weights('weights/lstm_f1_loss/saved_weights.h5')\n",
    "y_pred = tf.argmax(model.predict(X_test),axis = 1)\n",
    "print(classification_report(y_test, y_pred,zero_division=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
