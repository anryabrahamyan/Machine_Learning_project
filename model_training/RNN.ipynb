{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "182ecf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "95ac8c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/anry/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9aa8ed5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://medium.com/swlh/multi-label-text-classification-with-scikit-learn-and-tensorflow-257f9ee30536\n",
    "def decontract(sentence):\n",
    "    sentence = re.sub(r\"n\\'t\", \" not\", sentence)\n",
    "    sentence = re.sub(r\"\\'re\", \" are\", sentence)\n",
    "    sentence = re.sub(r\"\\'s\", \" is\", sentence)\n",
    "    sentence = re.sub(r\"\\'d\", \" would\", sentence)\n",
    "    sentence = re.sub(r\"\\'ll\", \" will\", sentence)\n",
    "    sentence = re.sub(r\"\\'t\", \" not\", sentence)\n",
    "    sentence = re.sub(r\"\\'ve\", \" have\", sentence)\n",
    "    sentence = re.sub(r\"\\'m\", \" am\", sentence)\n",
    "    return sentence\n",
    "\n",
    "def removePunctuation(sentence): \n",
    "    sentence = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n",
    "    sentence = re.sub(r'[.|,|)|(|\\|/]',r' ',sentence)\n",
    "    sentence = sentence.strip()\n",
    "    sentence = sentence.replace(\"\\n\",\" \")\n",
    "    return sentence\n",
    "\n",
    "def removeNumber(sentence):\n",
    "    alpha_sent = \"\"\n",
    "    for word in sentence.split():\n",
    "        alpha_word = re.sub('[^a-z A-Z]+', '', word)\n",
    "        alpha_sent += alpha_word\n",
    "        alpha_sent += \" \"\n",
    "    alpha_sent = alpha_sent.strip()\n",
    "    return alpha_sent\n",
    "\n",
    "def removeStopWords(sentence):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    sentence = sentence.split(' ')\n",
    "    filtered_sentence = [w for w in sentence if not w.lower() in stop_words]\n",
    "    return \" \".join(filtered_sentence)\n",
    "    \n",
    "\n",
    "def stemming(sentence):\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    stemmedSentence = \"\"\n",
    "    for word in sentence.split():\n",
    "        stem = stemmer.stem(word)\n",
    "        stemmedSentence += stem\n",
    "        stemmedSentence += \" \"\n",
    "    stemmedSentence = stemmedSentence.strip()\n",
    "    return stemmedSentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5e6d2fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = pd.read_csv('../datasets/train_preprocessed.csv').dropna()\n",
    "X_train,y_train = datasets[\"content\"].astype(\"string\"),datasets[\"sentiment\"].astype(\"category\").cat.codes\n",
    "\n",
    "maxlen = max(X_train.apply(lambda x:len(x)))+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c64bd698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = X_train.apply(lambda x: decontract(x))\n",
    "# X_train = X_train.apply(lambda x: removePunctuation(x))\n",
    "# X_train = X_train.apply(lambda x: removeNumber(x))\n",
    "# X_train = X_train.apply(lambda x: removeStopWords(x))\n",
    "# X_train = X_train.apply(lambda x: stemming(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "34351120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 know feel head get stuffier stuffier fun\n",
       "1                          mum sound humbl sweet thing ask\n",
       "2        star trek awesom kirk hot spock cool fun cool ...\n",
       "3        amaz thing keep onlin convers one place unfort...\n",
       "4        need water paper towel coke store feel sick go...\n",
       "                               ...                        \n",
       "26795                                excel never know lmao\n",
       "26796                          new dress look sort horribl\n",
       "26797    archetyp thing comm class studi archetyp popul...\n",
       "26798                                   jealous pour right\n",
       "26799                               road test book r scare\n",
       "Name: content, Length: 26741, dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "63415c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words=10000, lower=True)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_train = pad_sequences(X_train, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4b415202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    1,   55,   80,\n",
       "          7,   98,    5,  296,    9,  138, 6748,    6, 6748,    6,    8,\n",
       "          9,   26,  103], dtype=int32)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6cc4ed1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Flatten, LSTM, Input,Embedding,Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "max_words =10000\n",
    "# maxlen = max(X_train.apply(lambda x:len(x)))+1\n",
    "\n",
    "deep_inputs = Input(shape=(maxlen,))\n",
    "\n",
    "embedding_layer = Embedding(max_words,120, trainable=True)(deep_inputs)# weights=[embedding_matrix],\n",
    "\n",
    "\n",
    "LSTM_Layer_1 = LSTM(120,activation=\"tanh\",\n",
    "    recurrent_activation=\"sigmoid\",\n",
    "    use_bias=True,dropout=0.1,return_sequences=True)(embedding_layer)\n",
    "\n",
    "LSTM_Layer_2 = LSTM(120,activation=\"tanh\",\n",
    "    recurrent_activation=\"sigmoid\",\n",
    "    use_bias=True,dropout=0.1)(LSTM_Layer_1)\n",
    "\n",
    "\n",
    "dense_layer_1 = Dense(13, activation='sigmoid')(LSTM_Layer_2)\n",
    "model = Model(inputs=deep_inputs, outputs=dense_layer_1)\n",
    "model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), metrics=[  tf.keras.metrics.TruePositives(name='tp'),\n",
    "  tf.keras.metrics.FalsePositives(name='fp'),\n",
    "  tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "  tf.keras.metrics.FalseNegatives(name='fn'), \n",
    "  tf.keras.metrics.Precision(name='precision'),\n",
    "  tf.keras.metrics.Recall(name='recall'),\n",
    "  tf.keras.metrics.CategoricalAccuracy(name='acc'),\n",
    "  tf.keras.metrics.AUC(name='auc')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "07d544c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1337/1337 [==============================] - 564s 405ms/step - loss: 0.2388 - tp: 14.0000 - fp: 132.0000 - tn: 256572.0000 - fn: 21378.0000 - precision: 0.0959 - recall: 6.5445e-04 - acc: 0.2145 - auc: 0.7667 - val_loss: 0.2285 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 64188.0000 - val_fn: 5349.0000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_acc: 0.2539 - val_auc: 0.7957\n",
      "Epoch 2/4\n",
      "1337/1337 [==============================] - 466s 349ms/step - loss: 0.2209 - tp: 184.0000 - fp: 168.0000 - tn: 256536.0000 - fn: 21208.0000 - precision: 0.5227 - recall: 0.0086 - acc: 0.3079 - auc: 0.8156 - val_loss: 0.2198 - val_tp: 79.0000 - val_fp: 51.0000 - val_tn: 64137.0000 - val_fn: 5270.0000 - val_precision: 0.6077 - val_recall: 0.0148 - val_acc: 0.3287 - val_auc: 0.8183\n",
      "Epoch 3/4\n",
      "1337/1337 [==============================] - 501s 374ms/step - loss: 0.2071 - tp: 1749.0000 - fp: 1254.0000 - tn: 255450.0000 - fn: 19643.0000 - precision: 0.5824 - recall: 0.0818 - acc: 0.3869 - auc: 0.8453 - val_loss: 0.2193 - val_tp: 247.0000 - val_fp: 188.0000 - val_tn: 64000.0000 - val_fn: 5102.0000 - val_precision: 0.5678 - val_recall: 0.0462 - val_acc: 0.3350 - val_auc: 0.8218\n",
      "Epoch 4/4\n",
      "1337/1337 [==============================] - 540s 404ms/step - loss: 0.1957 - tp: 3271.0000 - fp: 2017.0000 - tn: 254687.0000 - fn: 18121.0000 - precision: 0.6186 - recall: 0.1529 - acc: 0.4309 - auc: 0.8659 - val_loss: 0.2240 - val_tp: 561.0000 - val_fp: 685.0000 - val_tn: 63503.0000 - val_fn: 4788.0000 - val_precision: 0.4502 - val_recall: 0.1049 - val_acc: 0.3236 - val_auc: 0.8127\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0e79543fd0>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,pd.get_dummies(y_train),validation_split=0.2,batch_size=16,epochs = 4,workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f4804223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        74\n",
      "           1       0.00      0.00      0.00       120\n",
      "           2       0.00      0.00      0.00       546\n",
      "           3       0.00      0.00      0.00       509\n",
      "           4       0.00      0.00      0.00      1190\n",
      "           5       0.42      0.56      0.48      3488\n",
      "           6       0.00      0.00      0.00       886\n",
      "           7       0.49      0.64      0.55      2573\n",
      "           8       0.59      0.63      0.61      5744\n",
      "           9       0.00      0.00      0.00      1022\n",
      "          10       0.64      0.01      0.02      3459\n",
      "          11       0.00      0.00      0.00      1465\n",
      "          12       0.37      0.83      0.51      5665\n",
      "\n",
      "    accuracy                           0.45     26741\n",
      "   macro avg       0.19      0.20      0.17     26741\n",
      "weighted avg       0.39      0.45      0.36     26741\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anry/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/anry/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/anry/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "y_pred = np.argmax(model.predict(X_train),axis = 1)\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5c248873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8     0.214801\n",
       "12    0.211847\n",
       "5     0.130436\n",
       "10    0.129352\n",
       "7     0.096219\n",
       "11    0.054785\n",
       "4     0.044501\n",
       "9     0.038218\n",
       "6     0.033133\n",
       "2     0.020418\n",
       "3     0.019034\n",
       "1     0.004487\n",
       "0     0.002767\n",
       "dtype: float64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f3a8501e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26741,)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_pred,axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f716d748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26741"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720efee1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
