{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-03-15T14:28:01.287849Z",
     "iopub.status.busy": "2022-03-15T14:28:01.287469Z",
     "iopub.status.idle": "2022-03-15T14:28:01.328463Z",
     "shell.execute_reply": "2022-03-15T14:28:01.327141Z",
     "shell.execute_reply.started": "2022-03-15T14:28:01.287753Z"
    }
   },
   "source": [
    "#BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./opt/anaconda3/lib/python3.8/site-packages (1.0.5)\n",
      "Requirement already satisfied: pytz>=2017.2 in ./opt/anaconda3/lib/python3.8/site-packages (from pandas) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in ./opt/anaconda3/lib/python3.8/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in ./opt/anaconda3/lib/python3.8/site-packages (from pandas) (1.22.3)\n",
      "Requirement already satisfied: six>=1.5 in ./opt/anaconda3/lib/python3.8/site-packages (from python-dateutil>=2.6.1->pandas) (1.15.0)\n",
      "Requirement already satisfied: numpy in ./opt/anaconda3/lib/python3.8/site-packages (1.22.3)\n",
      "Requirement already satisfied: matplotlib in ./opt/anaconda3/lib/python3.8/site-packages (3.2.2)\n",
      "Requirement already satisfied: numpy>=1.11 in ./opt/anaconda3/lib/python3.8/site-packages (from matplotlib) (1.22.3)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in ./opt/anaconda3/lib/python3.8/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./opt/anaconda3/lib/python3.8/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in ./opt/anaconda3/lib/python3.8/site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./opt/anaconda3/lib/python3.8/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: six>=1.5 in ./opt/anaconda3/lib/python3.8/site-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n",
      "Requirement already satisfied: seaborn in ./opt/anaconda3/lib/python3.8/site-packages (0.10.1)\n",
      "Requirement already satisfied: matplotlib>=2.1.2 in ./opt/anaconda3/lib/python3.8/site-packages (from seaborn) (3.2.2)\n",
      "Requirement already satisfied: pandas>=0.22.0 in ./opt/anaconda3/lib/python3.8/site-packages (from seaborn) (1.0.5)\n",
      "Requirement already satisfied: numpy>=1.13.3 in ./opt/anaconda3/lib/python3.8/site-packages (from seaborn) (1.22.3)\n",
      "Requirement already satisfied: scipy>=1.0.1 in ./opt/anaconda3/lib/python3.8/site-packages (from seaborn) (1.5.0)\n",
      "Requirement already satisfied: cycler>=0.10 in ./opt/anaconda3/lib/python3.8/site-packages (from matplotlib>=2.1.2->seaborn) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in ./opt/anaconda3/lib/python3.8/site-packages (from matplotlib>=2.1.2->seaborn) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./opt/anaconda3/lib/python3.8/site-packages (from matplotlib>=2.1.2->seaborn) (1.2.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in ./opt/anaconda3/lib/python3.8/site-packages (from matplotlib>=2.1.2->seaborn) (2.4.7)\n",
      "Requirement already satisfied: pytz>=2017.2 in ./opt/anaconda3/lib/python3.8/site-packages (from pandas>=0.22.0->seaborn) (2020.1)\n",
      "Requirement already satisfied: six in ./opt/anaconda3/lib/python3.8/site-packages (from cycler>=0.10->matplotlib>=2.1.2->seaborn) (1.15.0)\n",
      "Requirement already satisfied: sklearn in ./opt/anaconda3/lib/python3.8/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in ./opt/anaconda3/lib/python3.8/site-packages (from sklearn) (0.23.1)\n",
      "Requirement already satisfied: joblib>=0.11 in ./opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->sklearn) (0.16.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in ./opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.5.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in ./opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.22.3)\n",
      "Requirement already satisfied: tensorflow in ./opt/anaconda3/lib/python3.8/site-packages (2.8.0)\n",
      "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.8.0.dev2021122109)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.15.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (4.1.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.44.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (13.0.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: gast>=0.2.1 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: numpy>=1.20 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.22.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: setuptools in ./opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (62.1.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.24.0)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: wheel>=0.26 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.6.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in ./opt/anaconda3/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in ./opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in ./opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./opt/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (5.0.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in ./opt/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./opt/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in ./opt/anaconda3/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: zipp>=0.5 in ./opt/anaconda3/lib/python3.8/site-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in ./opt/anaconda3/lib/python3.8/site-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in ./opt/anaconda3/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n",
      "Requirement already satisfied: transformers in ./opt/anaconda3/lib/python3.8/site-packages (4.18.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./opt/anaconda3/lib/python3.8/site-packages (from transformers) (5.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in ./opt/anaconda3/lib/python3.8/site-packages (from transformers) (20.4)\n",
      "Requirement already satisfied: requests in ./opt/anaconda3/lib/python3.8/site-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: numpy>=1.17 in ./opt/anaconda3/lib/python3.8/site-packages (from transformers) (1.22.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in ./opt/anaconda3/lib/python3.8/site-packages (from transformers) (0.11.6)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./opt/anaconda3/lib/python3.8/site-packages (from transformers) (4.47.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in ./opt/anaconda3/lib/python3.8/site-packages (from transformers) (0.5.1)\n",
      "Requirement already satisfied: filelock in ./opt/anaconda3/lib/python3.8/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: sacremoses in ./opt/anaconda3/lib/python3.8/site-packages (from transformers) (0.0.49)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./opt/anaconda3/lib/python3.8/site-packages (from transformers) (2020.6.8)\n",
      "Requirement already satisfied: six in ./opt/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->transformers) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in ./opt/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in ./opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in ./opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (2.0.12)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./opt/anaconda3/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
      "Requirement already satisfied: click in ./opt/anaconda3/lib/python3.8/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in ./opt/anaconda3/lib/python3.8/site-packages (from sacremoses->transformers) (0.16.0)\n",
      "Requirement already satisfied: nltk in ./opt/anaconda3/lib/python3.8/site-packages (3.5)\n",
      "Requirement already satisfied: click in ./opt/anaconda3/lib/python3.8/site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: tqdm in ./opt/anaconda3/lib/python3.8/site-packages (from nltk) (4.47.0)\n",
      "Requirement already satisfied: regex in ./opt/anaconda3/lib/python3.8/site-packages (from nltk) (2020.6.8)\n",
      "Requirement already satisfied: joblib in ./opt/anaconda3/lib/python3.8/site-packages (from nltk) (0.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "!pip install seaborn\n",
    "!pip install sklearn\n",
    "!pip install tensorflow\n",
    "!pip install transformers\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip uninstall transformers y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-text in ./opt/anaconda3/lib/python3.8/site-packages (2.8.1)\n",
      "Requirement already satisfied: tensorflow<2.9,>=2.8.0 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorflow-text) (2.8.0)\n",
      "Requirement already satisfied: tensorflow-hub>=0.8.0 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorflow-text) (0.12.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (4.1.1)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (1.12)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (1.44.0)\n",
      "Requirement already satisfied: setuptools in ./opt/anaconda3/lib/python3.8/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (62.1.0)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (2.8.0)\n",
      "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (2.8.0.dev2021122109)\n",
      "Requirement already satisfied: h5py>=2.9.0 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (3.1.0)\n",
      "Requirement already satisfied: gast>=0.2.1 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (0.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (1.6.3)\n",
      "Requirement already satisfied: six>=1.12.0 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (1.15.0)\n",
      "Requirement already satisfied: numpy>=1.20 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (1.22.3)\n",
      "Requirement already satisfied: libclang>=9.0.1 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (13.0.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (1.1.2)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (2.8.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (1.12.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (1.1.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (3.3.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (0.2.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (0.24.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (0.15.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (0.6.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (2.1.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (2.27.1)\n",
      "Requirement already satisfied: wheel>=0.26 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (0.37.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (1.8.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (2.6.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (3.3.6)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in ./opt/anaconda3/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (1.3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in ./opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in ./opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (2.0.12)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in ./opt/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (4.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./opt/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (5.0.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./opt/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (0.2.8)\n",
      "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in ./opt/anaconda3/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (4.11.3)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in ./opt/anaconda3/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (3.2.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in ./opt/anaconda3/lib/python3.8/site-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (0.4.8)\n",
      "Requirement already satisfied: zipp>=0.5 in ./opt/anaconda3/lib/python3.8/site-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (3.8.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-hub in ./opt/anaconda3/lib/python3.8/site-packages (0.12.0)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorflow-hub) (3.20.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorflow-hub) (1.22.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow-hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and Inspect the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ed = pd.read_csv('/Users/izabellamartirosyan/Desktop/tweet_emotions.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1956967341</td>\n",
       "      <td>empty</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956967666</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1956967696</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956967789</td>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1956968416</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tweet_id   sentiment                                            content\n",
       "0  1956967341       empty  @tiffanylue i know  i was listenin to bad habi...\n",
       "1  1956967666     sadness  Layin n bed with a headache  ughhhh...waitin o...\n",
       "2  1956967696     sadness                Funeral ceremony...gloomy friday...\n",
       "3  1956967789  enthusiasm               wants to hang out with friends SOON!\n",
       "4  1956968416     neutral  @dannycastillo We want to trade with someone w..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40000 entries, 0 to 39999\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   tweet_id   40000 non-null  int64 \n",
      " 1   sentiment  40000 non-null  object\n",
      " 2   content    40000 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 937.6+ KB\n"
     ]
    }
   ],
   "source": [
    "ed.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 40000 rows and 3 columns in the dataset. For text classification, we are interested in the content and sentiment column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ed.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no duplicates and there can't be outliers since both are text columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ed1 = ed.copy() #make a seperate copy of the original dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['empty', 'sadness', 'enthusiasm', 'neutral', 'worry', 'surprise',\n",
       "       'love', 'fun', 'hate', 'happiness', 'boredom', 'relief', 'anger'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check for the unique values in the sentiment column\n",
    "ed1.sentiment.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ed1.sentiment.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral       8638\n",
       "worry         8459\n",
       "happiness     5209\n",
       "sadness       5165\n",
       "love          3842\n",
       "surprise      2187\n",
       "fun           1776\n",
       "relief        1526\n",
       "hate          1323\n",
       "empty          827\n",
       "enthusiasm     759\n",
       "boredom        179\n",
       "anger          110\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ed1.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fae08fbfac0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (12,8))\n",
    "sns.countplot(y=ed1.sentiment,data = ed1,order = ed1.sentiment.value_counts().index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grouping together hate and anger under the label hate/anger and empty and boredom under the label empty/bore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels(sentiment):\n",
    "    if sentiment=='hate' or sentiment == 'anger':\n",
    "        return 'hate/anger'\n",
    "    elif sentiment == 'empty' or sentiment ==  'boredom':\n",
    "        return 'empty/boredom'\n",
    "    else:\n",
    "        return sentiment\n",
    "\n",
    "ed1['sentiment'] = ed1.apply(lambda x: labels(x['sentiment']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral          8638\n",
       "worry            8459\n",
       "happiness        5209\n",
       "sadness          5165\n",
       "love             3842\n",
       "surprise         2187\n",
       "fun              1776\n",
       "relief           1526\n",
       "hate/anger       1433\n",
       "empty/boredom    1006\n",
       "enthusiasm        759\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ed1.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"@ cayogial i wanted to come to BZ this summer :/ not so sure anymore... a teacher's life in the summer SUCKS\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check random tweet from content series\n",
    "ed1.content[99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hate/anger'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ed1.sentiment[99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "tt = TweetTokenizer()\n",
    "ed1['tokenize_content'] = ed1.content.str.lower().apply(tt.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@',\n",
       " 'cayogial',\n",
       " 'i',\n",
       " 'wanted',\n",
       " 'to',\n",
       " 'come',\n",
       " 'to',\n",
       " 'bz',\n",
       " 'this',\n",
       " 'summer',\n",
       " ':/',\n",
       " 'not',\n",
       " 'so',\n",
       " 'sure',\n",
       " 'anymore',\n",
       " '...',\n",
       " 'a',\n",
       " \"teacher's\",\n",
       " 'life',\n",
       " 'in',\n",
       " 'the',\n",
       " 'summer',\n",
       " 'sucks']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ed1.tokenize_content[99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer \n",
    "def lemmatize_text(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return [lemmatizer.lemmatize(w) for w in text]\n",
    "    \n",
    "ed1['tokenize_lemmatized_content'] = ed1['tokenize_content'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@',\n",
       " 'cayogial',\n",
       " 'i',\n",
       " 'wanted',\n",
       " 'to',\n",
       " 'come',\n",
       " 'to',\n",
       " 'bz',\n",
       " 'this',\n",
       " 'summer',\n",
       " ':/',\n",
       " 'not',\n",
       " 'so',\n",
       " 'sure',\n",
       " 'anymore',\n",
       " '...',\n",
       " 'a',\n",
       " \"teacher's\",\n",
       " 'life',\n",
       " 'in',\n",
       " 'the',\n",
       " 'summer',\n",
       " 'suck']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ed1.tokenize_lemmatized_content[99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/izabellamartirosyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "ed1['text']=ed1.tokenize_lemmatized_content.apply(lambda x: [item for item in x if item not in stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@',\n",
       " 'cayogial',\n",
       " 'wanted',\n",
       " 'come',\n",
       " 'bz',\n",
       " 'summer',\n",
       " ':/',\n",
       " 'sure',\n",
       " 'anymore',\n",
       " '...',\n",
       " \"teacher's\",\n",
       " 'life',\n",
       " 'summer',\n",
       " 'suck']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ed1.text[99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "      <th>tokenize_content</th>\n",
       "      <th>tokenize_lemmatized_content</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1956967341</td>\n",
       "      <td>empty/boredom</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "      <td>[@tiffanylue, i, know, i, was, listenin, to, b...</td>\n",
       "      <td>[@tiffanylue, i, know, i, wa, listenin, to, ba...</td>\n",
       "      <td>[@tiffanylue, know, wa, listenin, bad, habit, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956967666</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "      <td>[layin, n, bed, with, a, headache, ughhhh, ......</td>\n",
       "      <td>[layin, n, bed, with, a, headache, ughhhh, ......</td>\n",
       "      <td>[layin, n, bed, headache, ughhhh, ..., waitin,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1956967696</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "      <td>[funeral, ceremony, ..., gloomy, friday, ...]</td>\n",
       "      <td>[funeral, ceremony, ..., gloomy, friday, ...]</td>\n",
       "      <td>[funeral, ceremony, ..., gloomy, friday, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956967789</td>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "      <td>[wants, to, hang, out, with, friends, soon, !]</td>\n",
       "      <td>[want, to, hang, out, with, friend, soon, !]</td>\n",
       "      <td>[want, hang, friend, soon, !]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1956968416</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "      <td>[@dannycastillo, we, want, to, trade, with, so...</td>\n",
       "      <td>[@dannycastillo, we, want, to, trade, with, so...</td>\n",
       "      <td>[@dannycastillo, want, trade, someone, ha, hou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tweet_id      sentiment  \\\n",
       "0  1956967341  empty/boredom   \n",
       "1  1956967666        sadness   \n",
       "2  1956967696        sadness   \n",
       "3  1956967789     enthusiasm   \n",
       "4  1956968416        neutral   \n",
       "\n",
       "                                             content  \\\n",
       "0  @tiffanylue i know  i was listenin to bad habi...   \n",
       "1  Layin n bed with a headache  ughhhh...waitin o...   \n",
       "2                Funeral ceremony...gloomy friday...   \n",
       "3               wants to hang out with friends SOON!   \n",
       "4  @dannycastillo We want to trade with someone w...   \n",
       "\n",
       "                                    tokenize_content  \\\n",
       "0  [@tiffanylue, i, know, i, was, listenin, to, b...   \n",
       "1  [layin, n, bed, with, a, headache, ughhhh, ......   \n",
       "2      [funeral, ceremony, ..., gloomy, friday, ...]   \n",
       "3     [wants, to, hang, out, with, friends, soon, !]   \n",
       "4  [@dannycastillo, we, want, to, trade, with, so...   \n",
       "\n",
       "                         tokenize_lemmatized_content  \\\n",
       "0  [@tiffanylue, i, know, i, wa, listenin, to, ba...   \n",
       "1  [layin, n, bed, with, a, headache, ughhhh, ......   \n",
       "2      [funeral, ceremony, ..., gloomy, friday, ...]   \n",
       "3       [want, to, hang, out, with, friend, soon, !]   \n",
       "4  [@dannycastillo, we, want, to, trade, with, so...   \n",
       "\n",
       "                                                text  \n",
       "0  [@tiffanylue, know, wa, listenin, bad, habit, ...  \n",
       "1  [layin, n, bed, headache, ughhhh, ..., waitin,...  \n",
       "2      [funeral, ceremony, ..., gloomy, friday, ...]  \n",
       "3                      [want, hang, friend, soon, !]  \n",
       "4  [@dannycastillo, want, trade, someone, ha, hou...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ed1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40000 entries, 0 to 39999\n",
      "Data columns (total 6 columns):\n",
      " #   Column                       Non-Null Count  Dtype \n",
      "---  ------                       --------------  ----- \n",
      " 0   tweet_id                     40000 non-null  int64 \n",
      " 1   sentiment                    40000 non-null  object\n",
      " 2   content                      40000 non-null  object\n",
      " 3   tokenize_content             40000 non-null  object\n",
      " 4   tokenize_lemmatized_content  40000 non-null  object\n",
      " 5   text                         40000 non-null  object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "ed1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [@tiffanylue, know, wa, listenin, bad, habit, ...\n",
       "1        [layin, n, bed, headache, ughhhh, ..., waitin,...\n",
       "2            [funeral, ceremony, ..., gloomy, friday, ...]\n",
       "3                            [want, hang, friend, soon, !]\n",
       "4        [@dannycastillo, want, trade, someone, ha, hou...\n",
       "                               ...                        \n",
       "39995                                   [@johnlloydtaylor]\n",
       "39996                           [happy, mother, day, love]\n",
       "39997    [happy, mother's, day, mommy, ,, woman, man, l...\n",
       "39998    [@niariley, wassup, beautiful, !, !, !, follow...\n",
       "39999    [@mopedronin, bullet, train, tokyo, gf, visiti...\n",
       "Name: text, Length: 40000, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ed1.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ed1['text'] = ed1['text'].apply(lambda x: str(x).replace(',','').lstrip('[').rstrip(']')).str.replace(\"'\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ed2 = ed1[['text','sentiment']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@tiffanylue know wa listenin bad habit earlier...</td>\n",
       "      <td>empty/boredom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>layin n bed headache ughhhh ... waitin call ...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>funeral ceremony ... gloomy friday ...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>want hang friend soon !</td>\n",
       "      <td>enthusiasm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@dannycastillo want trade someone ha houston t...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text      sentiment\n",
       "0  @tiffanylue know wa listenin bad habit earlier...  empty/boredom\n",
       "1    layin n bed headache ughhhh ... waitin call ...        sadness\n",
       "2             funeral ceremony ... gloomy friday ...        sadness\n",
       "3                            want hang friend soon !     enthusiasm\n",
       "4  @dannycastillo want trade someone ha houston t...        neutral"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ed2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 2)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ed2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into Training and Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train_unenc, y_test_unenc = train_test_split(\\\n",
    "    ed2.text,ed2.sentiment,test_size = 0.35,stratify = ed1.sentiment )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26000,) (26000,) (14000,) (14000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,y_train_unenc.shape,X_test.shape,y_test_unenc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37394                            @michellecorydon thanks !\n",
       "18356                                      youtube working\n",
       "24473    @emily_morden .. \"richards\" . \"ill\" see / get ...\n",
       "27562                     \"lets\" continue productive today\n",
       "2784                   @redjotter  . seems cruel condition\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37394    happiness\n",
       "18356      sadness\n",
       "24473    happiness\n",
       "27562      neutral\n",
       "2784         worry\n",
       "Name: sentiment, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_unenc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral          5615\n",
       "worry            5498\n",
       "happiness        3386\n",
       "sadness          3357\n",
       "love             2497\n",
       "surprise         1422\n",
       "fun              1154\n",
       "relief            992\n",
       "hate/anger        932\n",
       "empty/boredom     654\n",
       "enthusiasm        493\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_unenc.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral          3023\n",
       "worry            2961\n",
       "happiness        1823\n",
       "sadness          1808\n",
       "love             1345\n",
       "surprise          765\n",
       "fun               622\n",
       "relief            534\n",
       "hate/anger        501\n",
       "empty/boredom     352\n",
       "enthusiasm        266\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_unenc.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21596153846153845 0.21592857142857144\n"
     ]
    }
   ],
   "source": [
    "print(5615/y_train_unenc.shape[0],3023/y_test_unenc.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01896153846153846 0.019\n"
     ]
    }
   ],
   "source": [
    "print(493/y_train_unenc.shape[0],266/y_test_unenc.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preprocessing the y_train_unenc and y_test_unenc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There 11 type of emotions present in the sentiment column. For feeding it into deep neural network, we will first convert them into labels and then encode it using one hot encoders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_enc = label_encoder.fit_transform(y_train_unenc)\n",
    "y_test_enc = label_encoder.fit_transform(y_test_unenc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(y_train_enc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 8, 3, ..., 1, 6, 2])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: \\ \n",
      "The environment is inconsistent, please check the package plan carefully\n",
      "The following packages are causing the inconsistency:\n",
      "\n",
      "  - defaults/osx-64::matplotlib-base==3.2.2=py38h5670ca0_0\n",
      "  - defaults/osx-64::mkl_random==1.1.1=py38h959d312_0\n",
      "  - defaults/osx-64::statsmodels==0.11.1=py38haf1e3a3_0\n",
      "  - defaults/osx-64::astropy==4.0.1.post1=py38h01d97ff_1\n",
      "  - defaults/osx-64::bottleneck==1.3.2=py38hf1fa96c_1\n",
      "  - defaults/noarch::numpydoc==1.1.0=py_0\n",
      "  - defaults/osx-64::conda-build==3.18.11=py38_0\n",
      "  - defaults/noarch::imageio==2.9.0=py_0\n",
      "  - defaults/osx-64::pywavelets==1.1.1=py38h1de35cc_0\n",
      "  - defaults/osx-64::mkl_fft==1.1.0=py38hc64f4ea_0\n",
      "  - defaults/noarch::anaconda-project==0.8.4=py_0\n",
      "  - defaults/osx-64::bokeh==2.1.1=py38_0\n",
      "  - defaults/osx-64::scipy==1.5.0=py38hbab996c_0\n",
      "  - conda-forge/osx-64::conda==4.12.0=py38h50d1736_0\n",
      "  - defaults/osx-64::patsy==0.5.1=py38_0\n",
      "  - defaults/osx-64::_ipyw_jlab_nb_ext_conf==0.1.0=py38_0\n",
      "  - defaults/osx-64::anaconda-client==1.7.2=py38_0\n",
      "  - defaults/osx-64::anaconda==2020.07=py38_0\n",
      "  - defaults/osx-64::spyder==4.1.4=py38_0\n",
      "  - defaults/osx-64::numba==0.50.1=py38h959d312_1\n",
      "  - defaults/osx-64::numexpr==2.7.1=py38hce01a72_0\n",
      "  - defaults/noarch::sphinx==3.1.2=py_0\n",
      "  - defaults/osx-64::pandas==1.0.5=py38h959d312_0\n",
      "  - defaults/noarch::dask==2.20.0=py_0\n",
      "  - defaults/noarch::jupyterlab_server==1.2.0=py_0\n",
      "  - defaults/osx-64::h5py==2.10.0=py38h3134771_0\n",
      "  - defaults/osx-64::scikit-image==0.16.2=py38h6c726b0_0\n",
      "  - defaults/noarch::seaborn==0.10.1=py_0\n",
      "  - defaults/osx-64::scikit-learn==0.23.1=py38h603561c_0\n",
      "  - defaults/osx-64::bkcharts==0.2=py38_0\n",
      "  - defaults/osx-64::numpy==1.18.5=py38h1da2735_0\n",
      "  - defaults/osx-64::matplotlib==3.2.2=0\n",
      "  - defaults/osx-64::anaconda-navigator==1.9.12=py38_0\n",
      "  - defaults/noarch::jupyterlab==2.1.5=py_0\n",
      "  - defaults/osx-64::pytables==3.6.1=py38h4727e94_0\n",
      "failed with initial frozen solve. Retrying with flexible solve.\n",
      "Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: - \n",
      "The environment is inconsistent, please check the package plan carefully\n",
      "The following packages are causing the inconsistency:\n",
      "\n",
      "  - defaults/osx-64::matplotlib-base==3.2.2=py38h5670ca0_0\n",
      "  - defaults/osx-64::mkl_random==1.1.1=py38h959d312_0\n",
      "  - defaults/osx-64::statsmodels==0.11.1=py38haf1e3a3_0\n",
      "  - defaults/osx-64::astropy==4.0.1.post1=py38h01d97ff_1\n",
      "  - defaults/osx-64::bottleneck==1.3.2=py38hf1fa96c_1\n",
      "  - defaults/noarch::numpydoc==1.1.0=py_0\n",
      "  - defaults/osx-64::conda-build==3.18.11=py38_0\n",
      "  - defaults/noarch::imageio==2.9.0=py_0\n",
      "  - defaults/osx-64::pywavelets==1.1.1=py38h1de35cc_0\n",
      "  - defaults/osx-64::mkl_fft==1.1.0=py38hc64f4ea_0\n",
      "  - defaults/noarch::anaconda-project==0.8.4=py_0\n",
      "  - defaults/osx-64::bokeh==2.1.1=py38_0\n",
      "  - defaults/osx-64::scipy==1.5.0=py38hbab996c_0\n",
      "  - conda-forge/osx-64::conda==4.12.0=py38h50d1736_0\n",
      "  - defaults/osx-64::patsy==0.5.1=py38_0\n",
      "  - defaults/osx-64::_ipyw_jlab_nb_ext_conf==0.1.0=py38_0\n",
      "  - defaults/osx-64::anaconda-client==1.7.2=py38_0\n",
      "  - defaults/osx-64::anaconda==2020.07=py38_0\n",
      "  - defaults/osx-64::spyder==4.1.4=py38_0\n",
      "  - defaults/osx-64::numba==0.50.1=py38h959d312_1\n",
      "  - defaults/osx-64::numexpr==2.7.1=py38hce01a72_0\n",
      "  - defaults/noarch::sphinx==3.1.2=py_0\n",
      "  - defaults/osx-64::pandas==1.0.5=py38h959d312_0\n",
      "  - defaults/noarch::dask==2.20.0=py_0\n",
      "  - defaults/noarch::jupyterlab_server==1.2.0=py_0\n",
      "  - defaults/osx-64::h5py==2.10.0=py38h3134771_0\n",
      "  - defaults/osx-64::scikit-image==0.16.2=py38h6c726b0_0\n",
      "  - defaults/noarch::seaborn==0.10.1=py_0\n",
      "  - defaults/osx-64::scikit-learn==0.23.1=py38h603561c_0\n",
      "  - defaults/osx-64::bkcharts==0.2=py38_0\n",
      "  - defaults/osx-64::numpy==1.18.5=py38h1da2735_0\n",
      "  - defaults/osx-64::matplotlib==3.2.2=0\n",
      "  - defaults/osx-64::anaconda-navigator==1.9.12=py38_0\n",
      "  - defaults/noarch::jupyterlab==2.1.5=py_0\n",
      "  - defaults/osx-64::pytables==3.6.1=py38h4727e94\\ \n",
      "done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/izabellamartirosyan/opt/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - keras\n",
      "\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  _anaconda_depends  pkgs/main/osx-64::_anaconda_depends-2020.07-py38_0\n",
      "  charset-normalizer pkgs/main/noarch::charset-normalizer-2.0.4-pyhd3eb1b0_0\n",
      "  keras              pkgs/main/noarch::keras-2.6.0-pyhd3eb1b0_0\n",
      "  numpy-base         pkgs/main/osx-64::numpy-base-1.18.5-py38h3304bdc_0\n",
      "  requests           pkgs/main/noarch::requests-2.27.1-pyhd3eb1b0_0\n",
      "  typing_extensions  pkgs/main/noarch::typing_extensions-4.1.1-pyh06a4308_0\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates                               2020.6.24-0 --> 2022.4.26-hecd8cb5_0\n",
      "  certifi                                  2020.6.20-py38_0 --> 2021.10.8-py38hecd8cb5_2\n",
      "  openssl                                 1.1.1g-h1de35cc_0 --> 1.1.1n-hca72f7f_0\n",
      "\n",
      "The following packages will be DOWNGRADED:\n",
      "\n",
      "  anaconda                                   2020.07-py38_0 --> custom-py38_1\n",
      "\n",
      "\n",
      "Preparing transaction: done\n",
      "Verifying transaction: failed\n",
      "\n",
      "RemoveError: 'requests' is a dependency of conda and cannot be removed from\n",
      "conda's operating environment.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: np_utils in ./opt/anaconda3/lib/python3.8/site-packages (0.6.0)\n",
      "Requirement already satisfied: numpy>=1.0 in ./opt/anaconda3/lib/python3.8/site-packages (from np_utils) (1.22.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./Library/Caches/pip/wheels/2f/e9/19/d3d310a06735013bf467216222ebb92b1158c5d3ae006bf92a/keras_utils-1.0.13-py3-none-any.whl\n",
      "Requirement already satisfied: Keras>=2.1.5 in ./opt/anaconda3/lib/python3.8/site-packages (from keras.utils) (2.8.0)\n",
      "Installing collected packages: keras.utils\n",
      "Successfully installed keras.utils\n"
     ]
    }
   ],
   "source": [
    "!pip install keras.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xe but this version of numpy is 0xd",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version 0xe but this version of numpy is 0xd"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "SystemError: <built-in method __contains__ of dict object at 0x7fadf5b24340> returned a result with an error set",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-89505a24ece6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Check the dependencies satisfy the minimal versions required.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdependency_versions_check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m from .utils import (\n\u001b[1;32m     32\u001b[0m     \u001b[0m_LazyModule\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/dependency_versions_check.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpkg\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"tokenizers\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;31m# must be loaded here, or else tqdm check may fail\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_tokenizers_available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_tokenizers_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mto_py_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m )\n\u001b[0;32m---> 45\u001b[0;31m from .hub import (\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0mCLOUDFRONT_DISTRIB_PREFIX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mDISABLE_TELEMETRY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfilelock\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFileLock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mhuggingface_hub\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHfFolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRepository\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_repo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_repo_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhoami\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/huggingface_hub/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mhub_mixin\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelHubMixin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPyTorchModelHubMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0minference_api\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInferenceApi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m from .keras_mixin import (\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0mKerasModelHubMixin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mfrom_pretrained_keras\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/huggingface_hub/keras_mixin.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_tf_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_typing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_pywrap_tensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# pylint: enable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tfe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmonitoring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/client/pywrap_tf_session.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# pylint: disable=invalid-import-order,g-bad-import-order, wildcard-import, unused-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pywrap_tf_session\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pywrap_tf_session\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_TF_SetTarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pywrap_tf_session\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_TF_SetConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: SystemError: <built-in method __contains__ of dict object at 0x7fadf5b24340> returned a result with an error set"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import Bert PreProcessor and Bert Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xe but this version of numpy is 0xd",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version 0xe but this version of numpy is 0xd"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "SystemError: <built-in method __contains__ of dict object at 0x7fadf5a662c0> returned a result with an error set",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-dbefaa41796e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTFBertModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bert-base-cased'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTFBertModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bert-base-cased'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Check the dependencies satisfy the minimal versions required.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdependency_versions_check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m from .utils import (\n\u001b[1;32m     32\u001b[0m     \u001b[0m_LazyModule\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/dependency_versions_check.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdependency_versions_table\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequire_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_version_core\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mto_py_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m )\n\u001b[0;32m---> 45\u001b[0;31m from .hub import (\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0mCLOUDFRONT_DISTRIB_PREFIX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mDISABLE_TELEMETRY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfilelock\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFileLock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mhuggingface_hub\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHfFolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRepository\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_repo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_repo_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhoami\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/huggingface_hub/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mhub_mixin\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelHubMixin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPyTorchModelHubMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0minference_api\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInferenceApi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m from .keras_mixin import (\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0mKerasModelHubMixin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mfrom_pretrained_keras\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/huggingface_hub/keras_mixin.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_tf_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_typing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_pywrap_tensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# pylint: enable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tfe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmonitoring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/client/pywrap_tf_session.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# pylint: disable=invalid-import-order,g-bad-import-order, wildcard-import, unused-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pywrap_tf_session\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pywrap_tf_session\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_TF_SetTarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pywrap_tf_session\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_TF_SetConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: SystemError: <built-in method __contains__ of dict object at 0x7fadf5a662c0> returned a result with an error set"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer,TFBertModel\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
    "bert = TFBertModel.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the input (takes some time) \n",
    "# here tokenizer using from bert-base-cased\n",
    "x_train = tokenizer(\n",
    "    text=X_train.tolist(),\n",
    "    add_special_tokens=True,\n",
    "    max_length = max_len,\n",
    "    truncation=True,\n",
    "    padding=True, \n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids = False,\n",
    "    return_attention_mask = True,\n",
    "    verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = tokenizer(\n",
    "    text=X_test.tolist(),\n",
    "    add_special_tokens=True,\n",
    "    max_length = max_len,\n",
    "    truncation=True,\n",
    "    padding=True, \n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids = False,\n",
    "    return_attention_mask = True,\n",
    "    verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = x_train['input_ids']\n",
    "attention_mask = x_train['attention_mask']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xe but this version of numpy is 0xd",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version 0xe but this version of numpy is 0xd"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "SystemError: <built-in method __contains__ of dict object at 0x7fadf5b55b40> returned a result with an error set",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-162adc7f067a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitializers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTruncatedNormal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCategoricalCrossentropy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_typing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_pywrap_tensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# pylint: enable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tfe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmonitoring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/client/pywrap_tf_session.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# pylint: disable=invalid-import-order,g-bad-import-order, wildcard-import, unused-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pywrap_tf_session\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pywrap_tf_session\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_TF_SetTarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pywrap_tf_session\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_TF_SetConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: SystemError: <built-in method __contains__ of dict object at 0x7fadf5b55b40> returned a result with an error set"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bert layers\n",
    "input_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_ids\")\n",
    "input_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"attention_mask\")\n",
    "embeddings = bert(input_ids,attention_mask = input_mask)[0] \n",
    "out = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
    "out = Dense(128, activation='relu')(out)\n",
    "out = tf.keras.layers.Dropout(0.1)(out)\n",
    "out = Dense(64,activation = 'relu')(out)\n",
    "y = Dense(11,activation = 'softmax')(out)\n",
    "model = tf.keras.Model(inputs=[input_ids, input_mask], outputs=y)\n",
    "model.layers[2].trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(\n",
    "    learning_rate=5e-05, # this learning rate is for bert model , taken from huggingface website \n",
    "    epsilon=1e-08,\n",
    "    decay=0.01,\n",
    "    clipnorm=1.0)\n",
    "# Set loss and metrics\n",
    "loss =CategoricalCrossentropy(from_logits = True)\n",
    "metric = CategoricalAccuracy(\"balanced_accuracy\"),\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer = optimizer,\n",
    "    loss = loss, \n",
    "    metrics = metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_history = model.fit(\n",
    "    x ={'input_ids':x_train['input_ids'],'attention_mask':x_train['attention_mask']} ,\n",
    "    y = y_train,\n",
    "    validation_data = (\n",
    "    {'input_ids':x_test['input_ids'],'attention_mask':x_test['attention_mask']}, y_test\n",
    "    ),\n",
    "  epochs=1,\n",
    "  batch_size = 128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict=np.argmax(y_predicted, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test_enc, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test_enc, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cm, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
