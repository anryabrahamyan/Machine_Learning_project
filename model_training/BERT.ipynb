{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9edb1a96-602a-4863-87ac-6e812a9df020",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bleach==4.1.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from -r ../requirements.txt (line 1)) (4.1.0)\n",
      "Requirement already satisfied: more_itertools==8.12.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from -r ../requirements.txt (line 2)) (8.12.0)\n",
      "Requirement already satisfied: nlpaug==1.1.10 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from -r ../requirements.txt (line 3)) (1.1.10)\n",
      "Requirement already satisfied: pandas==1.4.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from -r ../requirements.txt (line 4)) (1.4.0)\n",
      "Requirement already satisfied: preprocessor==1.1.3 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from -r ../requirements.txt (line 5)) (1.1.3)\n",
      "Requirement already satisfied: streamlit==1.5.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from -r ../requirements.txt (line 6)) (1.5.1)\n",
      "Requirement already satisfied: tensorflow==2.8.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from -r ../requirements.txt (line 7)) (2.8.0)\n",
      "Requirement already satisfied: transformers==4.16.2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from -r ../requirements.txt (line 8)) (4.16.2)\n",
      "Requirement already satisfied: packaging in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from bleach==4.1.0->-r ../requirements.txt (line 1)) (21.3)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from bleach==4.1.0->-r ../requirements.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: webencodings in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from bleach==4.1.0->-r ../requirements.txt (line 1)) (0.5.1)\n",
      "Requirement already satisfied: requests>=2.22.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from nlpaug==1.1.10->-r ../requirements.txt (line 3)) (2.27.1)\n",
      "Requirement already satisfied: numpy>=1.16.2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from nlpaug==1.1.10->-r ../requirements.txt (line 3)) (1.22.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from pandas==1.4.0->-r ../requirements.txt (line 4)) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from pandas==1.4.0->-r ../requirements.txt (line 4)) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from streamlit==1.5.1->-r ../requirements.txt (line 6)) (9.0.1)\n",
      "Requirement already satisfied: base58 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from streamlit==1.5.1->-r ../requirements.txt (line 6)) (2.1.1)\n",
      "Requirement already satisfied: pympler>=0.9 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from streamlit==1.5.1->-r ../requirements.txt (line 6)) (1.0.1)\n",
      "Requirement already satisfied: pyarrow in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from streamlit==1.5.1->-r ../requirements.txt (line 6)) (7.0.0)\n",
      "Requirement already satisfied: validators in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from streamlit==1.5.1->-r ../requirements.txt (line 6)) (0.18.2)\n",
      "Requirement already satisfied: toml in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from streamlit==1.5.1->-r ../requirements.txt (line 6)) (0.10.2)\n",
      "Requirement already satisfied: cachetools>=4.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from streamlit==1.5.1->-r ../requirements.txt (line 6)) (5.0.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from streamlit==1.5.1->-r ../requirements.txt (line 6)) (3.1.27)\n",
      "Requirement already satisfied: altair>=3.2.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from streamlit==1.5.1->-r ../requirements.txt (line 6)) (4.2.0)\n",
      "Requirement already satisfied: tornado>=5.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from streamlit==1.5.1->-r ../requirements.txt (line 6)) (6.1)\n",
      "Requirement already satisfied: blinker in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from streamlit==1.5.1->-r ../requirements.txt (line 6)) (1.4)\n",
      "Requirement already satisfied: astor in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from streamlit==1.5.1->-r ../requirements.txt (line 6)) (0.8.1)\n",
      "Requirement already satisfied: pydeck>=0.1.dev5 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from streamlit==1.5.1->-r ../requirements.txt (line 6)) (0.7.1)\n",
      "Requirement already satisfied: tzlocal in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from streamlit==1.5.1->-r ../requirements.txt (line 6)) (4.2)\n",
      "Requirement already satisfied: protobuf!=3.11,>=3.6.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from streamlit==1.5.1->-r ../requirements.txt (line 6)) (3.19.4)\n",
      "Requirement already satisfied: attrs in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from streamlit==1.5.1->-r ../requirements.txt (line 6)) (21.4.0)\n",
      "Requirement already satisfied: click>=7.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from streamlit==1.5.1->-r ../requirements.txt (line 6)) (8.1.3)\n",
      "Requirement already satisfied: watchdog in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from streamlit==1.5.1->-r ../requirements.txt (line 6)) (2.1.7)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorflow==2.8.0->-r ../requirements.txt (line 7)) (2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorflow==2.8.0->-r ../requirements.txt (line 7)) (4.1.1)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorflow==2.8.0->-r ../requirements.txt (line 7)) (1.0.0)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorflow==2.8.0->-r ../requirements.txt (line 7)) (2.8.0)\n",
      "Requirement already satisfied: gast>=0.2.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorflow==2.8.0->-r ../requirements.txt (line 7)) (0.5.3)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorflow==2.8.0->-r ../requirements.txt (line 7)) (13.0.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorflow==2.8.0->-r ../requirements.txt (line 7)) (0.24.0)\n",
      "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorflow==2.8.0->-r ../requirements.txt (line 7)) (2.8.0.dev2021122109)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorflow==2.8.0->-r ../requirements.txt (line 7)) (1.44.0)\n",
      "Requirement already satisfied: setuptools in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorflow==2.8.0->-r ../requirements.txt (line 7)) (60.9.3)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorflow==2.8.0->-r ../requirements.txt (line 7)) (3.6.0)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorflow==2.8.0->-r ../requirements.txt (line 7)) (2.8.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorflow==2.8.0->-r ../requirements.txt (line 7)) (1.1.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorflow==2.8.0->-r ../requirements.txt (line 7)) (0.2.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorflow==2.8.0->-r ../requirements.txt (line 7)) (1.6.3)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorflow==2.8.0->-r ../requirements.txt (line 7)) (1.14.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorflow==2.8.0->-r ../requirements.txt (line 7)) (3.3.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorflow==2.8.0->-r ../requirements.txt (line 7)) (1.1.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from transformers==4.16.2->-r ../requirements.txt (line 8)) (0.5.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from transformers==4.16.2->-r ../requirements.txt (line 8)) (0.12.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from transformers==4.16.2->-r ../requirements.txt (line 8)) (4.64.0)\n",
      "Requirement already satisfied: sacremoses in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from transformers==4.16.2->-r ../requirements.txt (line 8)) (0.0.49)\n",
      "Requirement already satisfied: filelock in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from transformers==4.16.2->-r ../requirements.txt (line 8)) (3.6.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from transformers==4.16.2->-r ../requirements.txt (line 8)) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from transformers==4.16.2->-r ../requirements.txt (line 8)) (2022.4.24)\n",
      "Requirement already satisfied: jinja2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from altair>=3.2.0->streamlit==1.5.1->-r ../requirements.txt (line 6)) (3.0.3)\n",
      "Requirement already satisfied: toolz in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from altair>=3.2.0->streamlit==1.5.1->-r ../requirements.txt (line 6)) (0.11.2)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from altair>=3.2.0->streamlit==1.5.1->-r ../requirements.txt (line 6)) (4.4.0)\n",
      "Requirement already satisfied: entrypoints in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from altair>=3.2.0->streamlit==1.5.1->-r ../requirements.txt (line 6)) (0.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow==2.8.0->-r ../requirements.txt (line 7)) (0.37.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from gitpython!=3.1.19->streamlit==1.5.1->-r ../requirements.txt (line 6)) (4.0.9)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19->streamlit==1.5.1->-r ../requirements.txt (line 6)) (5.0.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit==1.5.1->-r ../requirements.txt (line 6)) (0.18.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from packaging->bleach==4.1.0->-r ../requirements.txt (line 1)) (3.0.7)\n",
      "Requirement already satisfied: traitlets>=4.3.2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from pydeck>=0.1.dev5->streamlit==1.5.1->-r ../requirements.txt (line 6)) (5.1.1)\n",
      "Requirement already satisfied: ipywidgets>=7.0.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from pydeck>=0.1.dev5->streamlit==1.5.1->-r ../requirements.txt (line 6)) (7.6.5)\n",
      "Requirement already satisfied: ipykernel>=5.1.2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from pydeck>=0.1.dev5->streamlit==1.5.1->-r ../requirements.txt (line 6)) (6.4.2)\n",
      "Requirement already satisfied: ipython-genutils in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==1.5.1->-r ../requirements.txt (line 6)) (0.2.0)\n",
      "Requirement already satisfied: ipython<8.0,>=7.23.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==1.5.1->-r ../requirements.txt (line 6)) (7.31.1)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==1.5.1->-r ../requirements.txt (line 6)) (1.5.1)\n",
      "Requirement already satisfied: jupyter-client<8.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==1.5.1->-r ../requirements.txt (line 6)) (7.1.2)\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==1.5.1->-r ../requirements.txt (line 6)) (0.1.3)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==1.5.1->-r ../requirements.txt (line 6)) (4.8.0)\n",
      "Requirement already satisfied: backcall in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==1.5.1->-r ../requirements.txt (line 6)) (0.2.0)\n",
      "Requirement already satisfied: pygments in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==1.5.1->-r ../requirements.txt (line 6)) (2.11.2)\n",
      "Requirement already satisfied: pickleshare in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==1.5.1->-r ../requirements.txt (line 6)) (0.7.5)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==1.5.1->-r ../requirements.txt (line 6)) (0.18.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==1.5.1->-r ../requirements.txt (line 6)) (3.0.27)\n",
      "Requirement already satisfied: decorator in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==1.5.1->-r ../requirements.txt (line 6)) (5.1.1)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==1.5.1->-r ../requirements.txt (line 6)) (1.0.2)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==1.5.1->-r ../requirements.txt (line 6)) (5.1.3)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==1.5.1->-r ../requirements.txt (line 6)) (3.5.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from jedi>=0.16->ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==1.5.1->-r ../requirements.txt (line 6)) (0.8.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from jinja2->altair>=3.2.0->streamlit==1.5.1->-r ../requirements.txt (line 6)) (2.1.0)\n",
      "Requirement already satisfied: pyzmq>=13 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from jupyter-client<8.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==1.5.1->-r ../requirements.txt (line 6)) (22.3.0)\n",
      "Requirement already satisfied: nest-asyncio>=1.5 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from jupyter-client<8.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==1.5.1->-r ../requirements.txt (line 6)) (1.5.4)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from jupyter-client<8.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==1.5.1->-r ../requirements.txt (line 6)) (4.9.2)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from pexpect>4.3->ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==1.5.1->-r ../requirements.txt (line 6)) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==1.5.1->-r ../requirements.txt (line 6)) (0.2.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests>=2.22.0->nlpaug==1.1.10->-r ../requirements.txt (line 3)) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests>=2.22.0->nlpaug==1.1.10->-r ../requirements.txt (line 3)) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests>=2.22.0->nlpaug==1.1.10->-r ../requirements.txt (line 3)) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests>=2.22.0->nlpaug==1.1.10->-r ../requirements.txt (line 3)) (1.26.9)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0->-r ../requirements.txt (line 7)) (3.3.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0->-r ../requirements.txt (line 7)) (1.8.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0->-r ../requirements.txt (line 7)) (0.6.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0->-r ../requirements.txt (line 7)) (0.4.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0->-r ../requirements.txt (line 7)) (2.6.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0->-r ../requirements.txt (line 7)) (2.0.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0->-r ../requirements.txt (line 7)) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0->-r ../requirements.txt (line 7)) (4.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.0->-r ../requirements.txt (line 7)) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow==2.8.0->-r ../requirements.txt (line 7)) (4.11.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow==2.8.0->-r ../requirements.txt (line 7)) (3.7.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0->-r ../requirements.txt (line 7)) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.0->-r ../requirements.txt (line 7)) (3.2.0)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==1.5.1->-r ../requirements.txt (line 6)) (6.4.8)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==1.5.1->-r ../requirements.txt (line 6)) (1.8.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==1.5.1->-r ../requirements.txt (line 6)) (0.13.1)\n",
      "Requirement already satisfied: nbconvert in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==1.5.1->-r ../requirements.txt (line 6)) (6.4.2)\n",
      "Requirement already satisfied: argon2-cffi in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==1.5.1->-r ../requirements.txt (line 6)) (21.3.0)\n",
      "Requirement already satisfied: prometheus-client in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==1.5.1->-r ../requirements.txt (line 6)) (0.13.1)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==1.5.1->-r ../requirements.txt (line 6)) (21.2.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==1.5.1->-r ../requirements.txt (line 6)) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==1.5.1->-r ../requirements.txt (line 6)) (2.21)\n",
      "Requirement already satisfied: defusedxml in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==1.5.1->-r ../requirements.txt (line 6)) (0.7.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==1.5.1->-r ../requirements.txt (line 6)) (1.5.0)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==1.5.1->-r ../requirements.txt (line 6)) (0.5.11)\n",
      "Requirement already satisfied: testpath in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==1.5.1->-r ../requirements.txt (line 6)) (0.6.0)\n",
      "Requirement already satisfied: jupyterlab-pygments in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==1.5.1->-r ../requirements.txt (line 6)) (0.1.2)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==1.5.1->-r ../requirements.txt (line 6)) (0.8.4)\n",
      "Requirement already satisfied: joblib in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from sacremoses->transformers==4.16.2->-r ../requirements.txt (line 8)) (1.1.0)\n",
      "Requirement already satisfied: pytz-deprecation-shim in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tzlocal->streamlit==1.5.1->-r ../requirements.txt (line 6)) (0.1.0.post0)\n",
      "Requirement already satisfied: tzdata in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from pytz-deprecation-shim->tzlocal->streamlit==1.5.1->-r ../requirements.txt (line 6)) (2022.1)\n",
      "Requirement already satisfied: sklearn in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from sklearn) (1.0.2)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from scikit-learn->sklearn) (1.8.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from scikit-learn->sklearn) (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.14.6 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from scikit-learn->sklearn) (1.22.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Requirement already satisfied: tensorflow in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (2.8.0)\n",
      "Collecting addons\n",
      "  Using cached AddOns-0.7.zip (34 kB)\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /home/studio-lab-user/.conda/envs/default/bin/python3.9 -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-r8usia01/addons_91fad6a269334d61906626a9b0fd41b9/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-r8usia01/addons_91fad6a269334d61906626a9b0fd41b9/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /tmp/pip-pip-egg-info-8q6sayj1\n",
      "         cwd: /tmp/pip-install-r8usia01/addons_91fad6a269334d61906626a9b0fd41b9/\n",
      "    Complete output (8 lines):\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"/tmp/pip-install-r8usia01/addons_91fad6a269334d61906626a9b0fd41b9/setup.py\", line 4, in <module>\n",
      "        import ez_setup\n",
      "      File \"/tmp/pip-install-r8usia01/addons_91fad6a269334d61906626a9b0fd41b9/ez_setup/__init__.py\", line 98\n",
      "        except pkg_resources.VersionConflict, e:\n",
      "                                            ^\n",
      "    SyntaxError: invalid syntax\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/4c/ff/aa57125eaab21e8ea5107138c6fb79b7ff7b96c7475cbe9ce01a0a62b99f/AddOns-0.7.zip#sha256=4d5f248c31db312081a3d562d1de433971e6cd2e94aeb00c4ebc08e22ea8f15c (from https://pypi.org/simple/addons/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "  Using cached AddOns-0.6.zip (33 kB)\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /home/studio-lab-user/.conda/envs/default/bin/python3.9 -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-r8usia01/addons_cc9fd9e12f2843719e2d1eb053dd6a94/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-r8usia01/addons_cc9fd9e12f2843719e2d1eb053dd6a94/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /tmp/pip-pip-egg-info-lq3b_5o1\n",
      "         cwd: /tmp/pip-install-r8usia01/addons_cc9fd9e12f2843719e2d1eb053dd6a94/\n",
      "    Complete output (8 lines):\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"/tmp/pip-install-r8usia01/addons_cc9fd9e12f2843719e2d1eb053dd6a94/setup.py\", line 4, in <module>\n",
      "        import ez_setup\n",
      "      File \"/tmp/pip-install-r8usia01/addons_cc9fd9e12f2843719e2d1eb053dd6a94/ez_setup/__init__.py\", line 94\n",
      "        except pkg_resources.VersionConflict, e:\n",
      "                                            ^\n",
      "    SyntaxError: invalid syntax\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/ee/e9/03898d175ac65a5bddef523c130382a4cfef90e9628cb01de5e485222bb0/AddOns-0.6.zip#sha256=65999ce99aaf4ba263be3d25f138eab2bd471a74c5f6a1c8022629a149e7099a (from https://pypi.org/simple/addons/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement addons (from versions: 0.6, 0.7)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for addons\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r ../requirements.txt\n",
    "!pip install sklearn\n",
    "!pip install tensorflow addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c94ae99-b274-46e8-aac6-b16018ab139a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from transformers import BertTokenizerFast, TFBertForSequenceClassification, pipeline\n",
    "from collections import Counter\n",
    "\n",
    "MAX_LENGTH = 200# Define the maximum number of words to tokenize (BERT can tokenize up to 512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b960ad6b-2c3f-4ea2-b59a-0699f58c7c07",
   "metadata": {},
   "source": [
    "# Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4885e82b-8a2c-4548-9b1e-6a25efe9aae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\",from_tf=True,)\n",
    "model = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\",)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba64460-9078-4069-866a-ed80520d2a99",
   "metadata": {},
   "source": [
    "# Load and transform the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d352861-63f9-4ab1-821a-70522bacd2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = pd.read_csv('../datasets/train_preprocessed.csv').dropna()\n",
    "X_train,y_train = datasets[\"content\"].astype(\"string\"),datasets[\"sentiment\"].astype(\"category\").cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f658508e-16ad-4bdd-b733-20cab74cd864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to encode text data in batches\n",
    "def batch_encode(tokenizer, texts, batch_size=256, max_length=MAX_LENGTH):\n",
    "    \"\"\"\"\"\"\"\"\"\n",
    "    A function that encodes a batch of texts and returns the texts'\n",
    "    corresponding encodings and attention masks that are ready to be fed \n",
    "    into a pre-trained transformer model.\n",
    "    \n",
    "    Input:\n",
    "        - tokenizer:   Tokenizer object from the PreTrainedTokenizer Class\n",
    "        - texts:       List of strings where each string represents a text\n",
    "        - batch_size:  Integer controlling number of texts in a batch\n",
    "        - max_length:  Integer controlling max number of words to tokenize in a given text\n",
    "    Output:\n",
    "        - input_ids:       sequence of texts encoded as a tf.Tensor object\n",
    "        - attention_mask:  the texts' attention mask encoded as a tf.Tensor object\n",
    "    \"\"\"\"\"\"\"\"\"\n",
    "    \n",
    "    input_ids = []\n",
    "    attention_mask = []\n",
    "    \n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        inputs = tokenizer.batch_encode_plus(batch,\n",
    "                                             max_length=max_length,\n",
    "                                             padding='max_length', #implements dynamic padding\n",
    "                                             truncation=True,\n",
    "                                             return_attention_mask=True,\n",
    "                                             return_token_type_ids=False\n",
    "                                             )\n",
    "        input_ids.extend(inputs['input_ids'])\n",
    "        attention_mask.extend(inputs['attention_mask'])\n",
    "    \n",
    "    \n",
    "    return tf.convert_to_tensor(input_ids), tf.convert_to_tensor(attention_mask)\n",
    "    \n",
    "    \n",
    "# Encode X_train\n",
    "X_train_ids, X_train_attention = batch_encode(tokenizer, X_train.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba4bc5a-72bf-43b9-8d67-f3d095bca338",
   "metadata": {},
   "source": [
    "Define F1 Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "515634a1-da14-41c6-946a-3c69ce15110e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def macro_double_soft_f1(y, y_hat):\n",
    "    \"\"\"Compute the macro soft F1-score as a cost (average 1 - soft-F1 across all labels).\n",
    "    Use probability values instead of binary predictions.\n",
    "    This version uses the computation of soft-F1 for both positive and negative class for each label.\n",
    "    \n",
    "    Args:\n",
    "        y (int32 Tensor): targets array of shape (BATCH_SIZE, N_LABELS)\n",
    "        y_hat (float32 Tensor): probability matrix from forward propagation of shape (BATCH_SIZE, N_LABELS)\n",
    "        \n",
    "    Returns:\n",
    "        cost (scalar Tensor): value of the cost function for the batch\n",
    "    \"\"\"\n",
    "    y = tf.cast(y, tf.float32)\n",
    "    y_hat = tf.cast(y_hat, tf.float32)\n",
    "    tp = tf.reduce_sum(y_hat * y, axis=0)\n",
    "    fp = tf.reduce_sum(y_hat * (1 - y), axis=0)\n",
    "    fn = tf.reduce_sum((1 - y_hat) * y, axis=0)\n",
    "    tn = tf.reduce_sum((1 - y_hat) * (1 - y), axis=0)\n",
    "    soft_f1_class1 = 2*tp / (2*tp + fn + fp + 1e-16)\n",
    "    soft_f1_class0 = 2*tn / (2*tn + fn + fp + 1e-16)\n",
    "    cost_class1 = 1 - soft_f1_class1 # reduce 1 - soft-f1_class1 in order to increase soft-f1 on class 1\n",
    "    cost_class0 = 1 - soft_f1_class0 # reduce 1 - soft-f1_class0 in order to increase soft-f1 on class 0\n",
    "    cost = 0.5 * (cost_class1 + cost_class0) # take into account both class 1 and class 0\n",
    "    macro_cost = tf.reduce_mean(cost) # average on all labels\n",
    "    return macro_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f210c6c-f927-4292-9dd4-bb6aee450bc0",
   "metadata": {},
   "source": [
    "# Create and compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e5a3e6f-2945-45e6-8438-939e4bbf8cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_layer = tf.keras.layers.Input(shape=(200,), \n",
    "                                        name='input_ids', \n",
    "                                        dtype='int32')\n",
    "input_attention_layer = tf.keras.layers.Input(shape=(200,), \n",
    "                                              name='input_attention', \n",
    "                                              dtype='int32')\n",
    "last_hidden_state = model.bert([input_ids_layer, input_attention_layer])[0]\n",
    "\n",
    "one_more = tf.keras.layers.AveragePooling1D(1,200)(last_hidden_state)\n",
    "pooling = tf.keras.layers.Reshape((768,))(one_more)\n",
    "output = tf.keras.layers.Dense(13,activation='softmax')(pooling)\n",
    "roberta = tf.keras.Model([input_ids_layer, input_attention_layer], output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ce62f54-89c7-463c-87c7-c098b4166f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'optimizer':tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "          'loss':tf.keras.losses.CategoricalCrossentropy(),\n",
    "          'metrics':[\"accuracy\"],# tf.keras.metrics.top_k_categorical_accuracy(k=3)\n",
    "}\n",
    "roberta.compile(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce222c0e-21a5-43b2-9f4e-514b8b51d310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)         [(None, 200)]        0           []                               \n",
      "                                                                                                  \n",
      " input_attention (InputLayer)   [(None, 200)]        0           []                               \n",
      "                                                                                                  \n",
      " bert (TFBertMainLayer)         TFBaseModelOutputWi  109482240   ['input_ids[0][0]',              \n",
      "                                thPoolingAndCrossAt               'input_attention[0][0]']        \n",
      "                                tentions(last_hidde                                               \n",
      "                                n_state=(None, 200,                                               \n",
      "                                 768),                                                            \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " average_pooling1d_1 (AveragePo  (None, 1, 768)      0           ['bert[0][0]']                   \n",
      " oling1D)                                                                                         \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 768)          0           ['average_pooling1d_1[0][0]']    \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 13)           9997        ['reshape_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109,492,237\n",
      "Trainable params: 109,492,237\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "roberta.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cf174d-fa87-489f-969d-21cb3abfdd5e",
   "metadata": {},
   "source": [
    "# Created weights for each class and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "768a81e4-5672-4d53-90f3-ac0d63d3e93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#counts = Counter(y_train)\n",
    "#weights = {i:1/j for i,j in counts.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d23db3-2515-47bf-a849-df851ba25340",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_for_sequence_classification_1/bert/pooler/dense/kernel:0', 'tf_bert_for_sequence_classification_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_for_sequence_classification_1/bert/pooler/dense/kernel:0', 'tf_bert_for_sequence_classification_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "1541/3343 [============>.................] - ETA: 3:03:01 - loss: 2.1980 - accuracy: 0.2132"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath=\"./esign_checkpoint/\",save_best_only=True,save_weights_only=False),\n",
    "]\n",
    "\n",
    "roberta.fit(x=[X_train_ids,X_train_attention],\n",
    "            y=pd.get_dummies(y_train),\n",
    "            batch_size=8,\n",
    "            epochs = 2,\n",
    "            workers = -1,\n",
    "           #validation_split=0.2,\n",
    "            callbacks = callbacks\n",
    "            #class_weight = weights\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da19ea36-52d7-4f8d-9fa6-5a806b81b782",
   "metadata": {},
   "outputs": [],
   "source": [
    " model.save_weights('./saved_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1d1bca-cffe-4125-8235-79b36f6d1c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.models.save_model(roberta,'./full_models/augmented')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31a358a3-c3b2-4cae-a769-530b89e7ed50",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/engine/training.py\", line 1801, in predict_function  *\n        return step_function(self, iterator)\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/engine/training.py\", line 1790, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/engine/training.py\", line 1783, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/engine/training.py\", line 1751, in predict_step\n        return self(x, training=False)\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    TypeError: Exception encountered when calling layer \"tf_bert_for_sequence_classification\" (type TFBertForSequenceClassification).\n    \n    in user code:\n    \n        File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/transformers/models/bert/modeling_tf_bert.py\", line 1752, in call  *\n            outputs = self.bert(\n        File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/transformers/models/bert/modeling_tf_bert.py\", line 787, in call\n            embedding_output = self.embeddings(\n    \n        TypeError: Exception encountered when calling layer \"embeddings\" (type TFBertEmbeddings).\n        \n        in user code:\n        \n            File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/transformers/models/bert/modeling_tf_bert.py\", line 190, in call  *\n                inputs_embeds = tf.gather(params=self.weight, indices=input_ids)\n        \n            TypeError: Value passed to parameter 'indices' has DataType string not in list of allowed values: int32, int64\n        \n        \n        Call arguments received:\n          • input_ids=tf.Tensor(shape=(None, 1), dtype=string)\n          • position_ids=None\n          • token_type_ids=tf.Tensor(shape=(None, 1), dtype=int32)\n          • inputs_embeds=None\n          • past_key_values_length=0\n          • training=False\n    \n    \n    Call arguments received:\n      • input_ids=tf.Tensor(shape=(None, 1), dtype=string)\n      • attention_mask=None\n      • token_type_ids=None\n      • position_ids=None\n      • head_mask=None\n      • inputs_embeds=None\n      • output_attentions=None\n      • output_hidden_states=None\n      • return_dict=None\n      • labels=None\n      • training=False\n      • kwargs=<class 'inspect._empty'>\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_75/282115371.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/engine/training.py\", line 1801, in predict_function  *\n        return step_function(self, iterator)\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/engine/training.py\", line 1790, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/engine/training.py\", line 1783, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/engine/training.py\", line 1751, in predict_step\n        return self(x, training=False)\n    File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    TypeError: Exception encountered when calling layer \"tf_bert_for_sequence_classification\" (type TFBertForSequenceClassification).\n    \n    in user code:\n    \n        File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/transformers/models/bert/modeling_tf_bert.py\", line 1752, in call  *\n            outputs = self.bert(\n        File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/transformers/models/bert/modeling_tf_bert.py\", line 787, in call\n            embedding_output = self.embeddings(\n    \n        TypeError: Exception encountered when calling layer \"embeddings\" (type TFBertEmbeddings).\n        \n        in user code:\n        \n            File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/transformers/models/bert/modeling_tf_bert.py\", line 190, in call  *\n                inputs_embeds = tf.gather(params=self.weight, indices=input_ids)\n        \n            TypeError: Value passed to parameter 'indices' has DataType string not in list of allowed values: int32, int64\n        \n        \n        Call arguments received:\n          • input_ids=tf.Tensor(shape=(None, 1), dtype=string)\n          • position_ids=None\n          • token_type_ids=tf.Tensor(shape=(None, 1), dtype=int32)\n          • inputs_embeds=None\n          • past_key_values_length=0\n          • training=False\n    \n    \n    Call arguments received:\n      • input_ids=tf.Tensor(shape=(None, 1), dtype=string)\n      • attention_mask=None\n      • token_type_ids=None\n      • position_ids=None\n      • head_mask=None\n      • inputs_embeds=None\n      • output_attentions=None\n      • output_hidden_states=None\n      • return_dict=None\n      • labels=None\n      • training=False\n      • kwargs=<class 'inspect._empty'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from tensorflow import keras\n",
    "import tqdm\n",
    "\n",
    "#load the test set\n",
    "datasets = pd.read_csv('../datasets/test_preprocessed.csv').dropna()# recreate for non-augmented\n",
    "X_test,y_test = datasets[\"content\"].astype(\"string\"),datasets[\"sentiment\"].astype(\"category\").cat.codes\n",
    "\n",
    "X_test_ids, X_test_attention = batch_encode(tokenizer, X_test.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9d7472-80cb-459a-ae1b-d48ba027402f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "722905bd-a358-4933-98a4-07110a3f4404",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm_callback = tfa.callbacks.TQDMProgressBar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f31bb0ae-66f8-4830-b810-c6eeb7deb84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "461/461 [==============================] - 183s 391ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        73\n",
      "           1       0.00      0.00      0.00       118\n",
      "           2       0.00      0.00      0.00       538\n",
      "           3       0.00      0.00      0.00       501\n",
      "           4       0.00      0.00      0.00       586\n",
      "           5       0.37      0.47      0.41      1719\n",
      "           6       0.67      0.05      0.10       873\n",
      "           7       0.58      0.43      0.49      1268\n",
      "           8       0.36      0.67      0.47      2825\n",
      "           9       0.81      0.04      0.08      1007\n",
      "          10       0.37      0.36      0.37      1704\n",
      "          11       0.39      0.04      0.08       722\n",
      "          12       0.32      0.51      0.39      2790\n",
      "\n",
      "    accuracy                           0.37     14724\n",
      "   macro avg       0.30      0.20      0.18     14724\n",
      "weighted avg       0.38      0.37      0.31     14724\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# normal EmoRoBERTa\n",
    "roberta.load_weights('weights/without_class_weights/saved_weights.h5')\n",
    "y_pred = tf.argmax(roberta.predict([X_test_ids, X_test_attention],workers = -1,callbacks=[tqdm_callback],verbose=1),axis = 1)\n",
    "print(classification_report(y_test, y_pred,zero_division = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40f4276e-f3a6-459b-addf-60d7d180baa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "461/461 [==============================] - 190s 412ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        73\n",
      "           1       0.04      0.37      0.07       118\n",
      "           2       0.00      0.00      0.00       538\n",
      "           3       0.10      0.01      0.01       501\n",
      "           4       0.20      0.12      0.15       586\n",
      "           5       0.38      0.11      0.18      1719\n",
      "           6       0.22      0.63      0.32       873\n",
      "           7       0.61      0.26      0.37      1268\n",
      "           8       0.37      0.34      0.35      2825\n",
      "           9       0.13      0.58      0.21      1007\n",
      "          10       0.30      0.32      0.31      1704\n",
      "          11       0.22      0.12      0.16       722\n",
      "          12       0.48      0.04      0.07      2790\n",
      "\n",
      "    accuracy                           0.24     14724\n",
      "   macro avg       0.23      0.22      0.17     14724\n",
      "weighted avg       0.34      0.24      0.22     14724\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# weighted EmoRoBERTa\n",
    "roberta.load_weights('weights/with_class_weights/saved_weights.h5')\n",
    "y_pred = tf.argmax(roberta.predict([X_test_ids, X_test_attention],workers = -1,callbacks=[tqdm_callback],verbose=1),axis = 1)\n",
    "print(classification_report(y_test, y_pred,zero_division = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35482e9a-8544-4c5c-8f43-a0bc8e7ae345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "461/461 [==============================] - 193s 418ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        73\n",
      "           1       0.00      0.00      0.00       118\n",
      "           2       0.00      0.00      0.00       538\n",
      "           3       0.00      0.00      0.00       501\n",
      "           4       0.00      0.00      0.00       586\n",
      "           5       0.00      0.00      0.00      1719\n",
      "           6       0.00      0.00      0.00       873\n",
      "           7       0.00      0.00      0.00      1268\n",
      "           8       0.36      0.27      0.31      2825\n",
      "           9       0.00      0.00      0.00      1007\n",
      "          10       0.00      0.00      0.00      1704\n",
      "          11       0.00      0.00      0.00       722\n",
      "          12       0.20      0.91      0.33      2790\n",
      "\n",
      "    accuracy                           0.22     14724\n",
      "   macro avg       0.04      0.09      0.05     14724\n",
      "weighted avg       0.11      0.22      0.12     14724\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# f1 loss EmoRoBERTa\n",
    "roberta.load_weights('weights/f1_loss/saved_weights.h5')\n",
    "y_pred = tf.argmax(roberta.predict([X_test_ids, X_test_attention],workers = -1,callbacks=[tqdm_callback],verbose=1),axis = 1)\n",
    "print(classification_report(y_test, y_pred,zero_division = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dff2fbc6-e39c-4cf6-8ef5-661e3f5f97d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "461/461 [==============================] - 192s 417ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        73\n",
      "           1       0.00      0.00      0.00       118\n",
      "           2       0.20      0.00      0.01       538\n",
      "           3       0.00      0.00      0.00       501\n",
      "           4       0.00      0.00      0.00       586\n",
      "           5       0.34      0.35      0.35      1719\n",
      "           6       0.42      0.58      0.49       873\n",
      "           7       0.45      0.50      0.48      1268\n",
      "           8       0.35      0.60      0.44      2825\n",
      "           9       0.44      0.22      0.29      1007\n",
      "          10       0.24      0.65      0.35      1704\n",
      "          11       0.20      0.02      0.03       722\n",
      "          12       0.43      0.04      0.07      2790\n",
      "\n",
      "    accuracy                           0.33     14724\n",
      "   macro avg       0.24      0.23      0.19     14724\n",
      "weighted avg       0.33      0.33      0.27     14724\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# augmented EmoRoBERTa\n",
    "roberta.load_weights('weights/augmented/saved_weights.h5')\n",
    "y_pred = tf.argmax(roberta.predict([X_test_ids, X_test_attention],workers = -1,callbacks=[tqdm_callback],verbose=1),axis = 1)\n",
    "print(classification_report(y_test, y_pred,zero_division = 0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
